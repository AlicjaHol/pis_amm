---
lang: pl
title: "Analiza szeregów czasowych - notowania giełdowe firm McDonald's oraz Starbucks"
author: "Alicja Hołowiecka, Matylda Jankowska, Marcin Dziadosz"
date: "23 12 2019"
output:
  
  pdf_document:
    toc: yes
    toc_depth: '4'
  html_document:
    theme: united
    toc: yes
    toc_depth: 4
  lang: pl
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
```

# Matylda!! (to do, to do, to do to do to do to doooooooo)

- estetycznie można trochę poprawić, np. jak są te testy kpss i inne, to na razie robiłam tak, żeby wyświetlało ten domyślny output, może zamiast tego zrób tak jak Ty robiłaś w testach, że zapisać p-value do zmiennej i opisać? i popatrz jak wyglądają wykresy, szczególnie w pdf, może coś nie wygląda tak dobrze jak się nam wydawało, np tytuły się nie mieszczą, albo coś jest za bardzo ściśnięte, np wiem że te wykresy dla wielomianu 4 stopnia z nieznanych dla mnie przyczyn strasznie odwalają w pdf

- jeżeli nadal coś się nie zgadza z tą kolejnością co Kozłowski proponował, to możesz poprzestawiać

- co do opisów firm - ze Starbucksa trzeba wywalić zdjęcia bo dupnie wyglądają w pdf. I nie wiem czy ewentualnie z neta nie skopiować ze dwa zdania więcej do każdego, bo jakoś blado. spadliśmy już do 44 stron także jest coraz lepiej :) a jak wywalimy rysunki to jeszcze kolejne 3-4 strony pójdą

- sprawdź, jak wyglądają tabelki w pdfie - czy na pewno każda się wyświetla dokładnie gdzie ma być. Jeśli nie, to np dla tabelek robionych poprzez `kable_styling` można dodawać parametry: ` position = 'center'`, `latex_options = "HOLD_position"` i powinny się trzymać swojego miejsca

- za Chiny ludowe nie wiem jak robić jakieś prognozy czy cokolwiek... bo ten holt winters to chyba tylko dla sezonowych idzie. zobacz czy coś się da, a jak nie to usuwaj to gadowstwo.

- co do ARIMY - opisałam tak, jak na laborkach robiliśmy, zobacz czy z tego modelu da się wyciągnąć reszty i robić na nich testy. jeśli się da, to zrób te testy

- myślałam żeby na koniec każdej z tych firm zrobić takie podsumowanie - że np dla McDonalda z modelów wielomianowych najlepszy był taki i taki, jego reszty spełniają/nie spełniają cośtam, oprócz tego dopasowaliśmy model ARIMA taki śmaki, jego reszty cośtam cośtam... jakieś takie ładne sratatata na zakończenie

- pracuj przede wszystkim nad McDonaldem, potem Marcin spisze do Starbucksa. Chociaż tam też oczywiście możesz coś zacząć żeby mu ułatwić.

## Wstęp

W tym raporcie przeanalizujemy dwa szeregi czasowe: notowania firm McDonald's oraz Starbucks z okresu dwóch lat (od początku 2018 do końca 2019). Na potrzeby oceny w raporcie pojawia się nie tylko sama analiza, ale też wszystkie polecenia w języku `R`, jakich używaliśmy w jej celu.

## Wczytanie bibliotek

Na początek wczytamy wszystkie potrzebne biblioteki. Biblioteka `tseries` przyda nam się m. in. do wczytania danych oraz wykonania testów na stacjonarność szeregu. Z pakietu `randtests` skorzystamy przy testach na losowość reszt. W bibliotece `nortest` znajduje się wiele testów na normalność. Dzięki paczce `lmtest` utworzymy modele wielomianowe różnego stopnia i zbadamy ich dopasowanie. W bibliotece `forecast` są m. in. funkcje dotyczące modeli ARIMA. Pakiety `stargazer`, `tables` i `kableExtra` pozwolą nam estetycznie wyświetlać tabele.

```{r biblioteki}
library(tseries)
library(randtests)
library(nortest)
library(lmtest)
library(forecast)
library(stargazer)
library(kableExtra)
library(tidyverse)
library(tables)
```

## McDonald's

### Opis firmy

McDonald's to największa na świecie sieć restauracji szybkiej obsługi. Obejmuje ona ponad 30 tys. restauracji, każdego dnia obsługujących ponad 46 mln osób w 119 krajach. Wartość marki McDonald's szacuje się na 24,7 mld dolarów.

### Wczytanie danych i rysunki

Dane pobieramy z `yahoo finance` za pomocą funkcji `get.hist.quote` i zamieniamy na typ numeryczny.

```{r wczytanie danych MCD}
mcd<- get.hist.quote(instrument = "MCD", provider = "yahoo",
                          quote = "Close", start = "2018-01-01", end = "2019-12-31")
mcd <- as.numeric(mcd)
```

Wykonamy rysunek przedstawiający notowania firmy McDonald's od 01-01-2018 do 31-12-2019

```{r rysunek notowań MCD}
plot(mcd, type = "l", xlab = "Indeks notowań", ylab = "USD", main = "Notowania McDonald's")
```
 
Na rysunku w ciągu tych dwóch lat wyraźnie widać trend rosnący.

### Wydzielanie trendu

Spróbujemy wydzielić część deterministyczną. Do tego celu posłużymy się metodami średnich ruchomych (prostą i wykładniczą).

#### Ruchoma średnia

Wykorzystamy metody ruchomych średnich, aby wygładzić szereg i zaobserwować ogólne trendy. Metoda średniej ruchomej ma na celu zmniejszenie rozrzutu razy $m+1$. 

W metodzie średniej ruchomej estymator części deterministycznej ma postać

$$\hat{f}(t) = \frac{1}{m+1}\sum_{k = 0}^{m}x_{t-k}$$

Do wykonania wygładzonych wykresów napisaliśmy funkcję `ruchoma`, której argumentami są `x` - szereg czasowy, `m` - paramter metody średniej ruchomej, `kolor` - kolor, na jaki dorysujemy wygładzoną linię na wykresie.

```{r funkcja ruchoma}
ruchoma <- function(x, m, kolor){
  t <- length(x)
  f <- NULL
  for(i in (m+1):t){
    f[i] <- mean(x[(i-m):i])
  }
  tytul = paste("Średnia ruchoma rzędu ", m)
  plot(x, type = "l", main = tytul, xlab = "Indeks notowań", ylab = "USD")
  lines((m+1):t, f[(m+1):t], lwd = 2, col = kolor)
}
```

Narysujemy wykresy dla kilku parametrów `m`.

```{r ruchoma MCD}
par(mfrow = c(2, 2))
ruchoma(mcd, 3, "red")
ruchoma(mcd, 10, "green")
ruchoma(mcd, 30, "blue")
ruchoma(mcd, 50, "pink")
par(mfrow = c(1, 1))
```


Jak widać, im większy parametr `m` przyjmiemy, tym bardziej wygładzony wykres uzyskujemy, ale też mniej dokładny.

#### Metoda wykładniczych wag ruchomej średniej

W metodzie ruchomej średniej obserwacje starsze i nowsze mają taką samą wagę, dlatego ta metoda jest mało dokładna. Skorzystamy teraz z dokładniejszej metody wykładniczych wag ruchomej średniej.

W tej metodzie estymator części deterministycznej ma postać:

$$\hat{f}(t) = \frac{1 - \eta}{1-\eta^t}\sum_{k = 0}^{t-1}\eta^kx_{t-k}$$

gdzie $\eta \in (0, 1)$

Skorzystamy z postaci rekurencyjnej:

$$\hat{f}(t)=\frac{1- \eta}{1 - \eta^t}\left[x_t+ \eta \frac{1 - \eta^{t-1}}{1 - \eta} \hat{f}(t-1) \right]$$

```{r funkcja wykładnicza}
wykladnicza <- function(x, mi, kolor){
  f <- NULL
  f[1] <- x[1]
  
  for (i in 2:length(x)){
    f[i] <- (1-mi)/(1-mi^i)*(x[i]+mi*(1-mi^(i-1))/(1-mi)*f[i-1])
  }
  tytul = paste("średnia ruchoma \n z wagami wykładniczymi \n z parametrem", mi)
  plot(x, type = "l", main = tytul, xlab = "Indeks notowań", ylab = "USD")
  lines(1:length(x), f, lwd = 2, col = kolor)
}
```


```{r wykładnicza MCD}
par(mfrow = c(2, 2))
wykladnicza(mcd, 0.2, "red")
wykladnicza(mcd, 0.5, "green")
wykladnicza(mcd, 0.7, "blue")
wykladnicza(mcd, 0.9, "pink")
par(mfrow = c(1, 1))
```


Podobnie jak w przypadku prostej metody średniej ruchomej - im większy parametr $\eta$, tym bardziej wygładzony wykres, ale i mniejsza dokładność. Jednakże, dokładność jest i tak większa niż w przypadku prostej metody ruchomej średniej.

### Dopasowanie wielomianu

#### Metoda różnicowa

Za pomocą metody różnicowej sprawdzimy, jaki stopień wielomianu byłby najbardziej odpowiedni.

```{r różnicowanie - rysunki MCD}
par(mfrow = c(2, 3))
for(i in 1:6){
ylab <- paste("różnice rzędu ", i)
plot(diff(mcd, differences = i), type = "l", xlab = "Indeks notowań", ylab = ylab)
abline(h = 0)}
par(mfrow=c(1,1))
```


Z wykresów można wysnuć wniosek, że największą stabilizację osiągamy przy różnicowaniu rzędu pierwszego lub drugiego. Wraz ze wzrostem rzędu różnicowania, wahania ulegają znacznemu rozszerzeniu.

Spróbujemy do danych dopasować wielomian stopnia 1, 2, 3 i 4.


```{r zmienna t MCD}
t <- 1:length(mcd)
```

#### Dopasowanie modelu liniowego

```{r model liniowy MCD}

mod1 <- lm(mcd~t)

```

```{r model liniowy MCD stargazer, results = 'asis'}
stargazer(mod1, header = F)
```

Zarówno wyraz wolny, jak i współczynnik kierunkowy są istotne statystycznie. $R^2$ wynosi około 74%.

```{r model liniowy - wykresy MCD} 
par(mfrow = c(1, 2))
plot(mcd, type = "l", main = "Model liniowy", xlab = "czas", ylab = "USD")
abline(mod1, col = "red")
plot(mod1$residuals, type = "l", 
     main = "Reszty modelu liniowego", xlab = "czas", ylab = "reszty")
abline(h=0)
par(mfrow = c(1, 1))
```

#### Dopasowanie wielomianem drugiego stopnia

Teraz stworzymy model wielomianowy drugiego stopnia.

```{r drugi stopień MCD}
mod2 <- lm(mcd~t+I(t^2))
```

```{r drugi stopień MCD stargazer, results = 'asis'}
stargazer(mod2, header = F)
```

Wszystkie współczynniki są istotne statystycznie. $R^2$ wynosi około 75%, a więc zmieniło się bardzo nieznacznie.

```{r drugi stopień - wykresy MCD}
par(mfrow = c(1, 2))
plot(mcd, type = "l", main = "Model wielomianowy \n drugiego stopnia", 
     xlab = "Indeks notowań", ylab = "USD")
lines(t, mod2$fitted.values, col = "red")
plot(mod2$residuals, type = "l", 
     main = "Reszty modelu \nwielomianowego \ndrugiego stopnia", 
     xlab = "Indeks notowań", ylab = "Reszty")
abline(h = 0)
par(mfrow = c(1, 1))
```

Model kwadratowy zachowuje się bardzo podobnie jak model liniowy.

#### Dopasowanie wielomianem trzeciego stopnia

Jako kolejny zbudowany zostanie model wielomianowy trzeciego stopnia.

```{r trzeci stopień MCD}
mod3 <- lm(mcd~t+I(t^2)+I(t^3))
```

```{r trzeci stopień MCD stargazer, results='asis'}
stargazer(mod3, header = F)
```

W modelu wielomianowym trzeciego stopnia wszystkie współczynniki są istotne statystycznie. $R^2$ wynosi 90%, a więc znacząco się poprawił w stosunku do poprzednich dwóch modeli.

```{r trzeci stopień - wykresy MCD}
par(mfrow = c(1, 2))
plot(mcd, type = "l", 
     main = "Model wielomianowy \ntrzeciego stopnia", 
     xlab = "Indeks notowań", ylab = "USD")
lines(t, mod3$fitted.values, col = "red")
plot(mod3$residuals, type = "l", 
     main = "Reszty modelu \nwielomianowego \ntrzeciego stopnia", 
     xlab = "Indeks notowań", ylab = "Reszty")
abline(h= 0)
par(mfrow = c(1, 1))
```

Widać, że reszty modelu mają mniejszy rozrzut niż poprzednio - teraz mamy skalę od -15 do 15, a wcześniej było od -20 do 20.

#### Dopasowanie wielomianem czwartego stopnia

```{r czwarty stopień MCD}
mod4 <- lm(mcd~t+I(t^2)+I(t^3)+I(t^4))
```

```{r czwarty stopień MCD stargazer, results='asis'}
stargazer(mod4, header = F)
```

```{r czwarty stopień - wykresy MCD}
par(mfrow = c(1, 2))
plot(mcd, type = "l", main = "Model wielomianowy \nczwartego stopnia", 
     xlab = "Indeks notowań", ylab = "USD")
lines(t, mod4$fitted.values, col = "red")
plot(mod3$residuals, type = "l", 
     main = "Reszty modelu \nwielomianowego \nczwartego stopnia", 
     xlab = "Indeks notowań", ylab = "Reszty")
abline(h= 0)
par(mfrow=c(1,1))
```

W modelu wielomianowym czwartego stopnia współczynnik przy $t^3$ jest nieistotny statystycznie, ale nie możemy go usunąć, ponieważ efekt wyższego rzędu ($t^4$) jest istotny. $R^2$ wynosi około 91%, więc niewiele się różni od modelu wielomianowego 3 stopnia. Reszty także znajdują się w podobnym przedziale jak w poprzednim modelu. Model z $t^4$ niewiele się różni od tego z $t^3$, dlatego do dalszych badań wykorzystamy model wielomianowy 3 stopnia.

### Testy na resztach modelu

Do danych dobraliśmy wcześniej model wielomianowy trzeciego stopnia. Teraz sprawdzimy, czy reszty tego modelu spełniają założenia:

- jednorodność wariancji

- normalność

- losowość


#### Jednorodność wariancji

Aby zbadać czy jednorodność reszt posłużymy się kilkoma popularnymi testami.

- Test `Breuscha-Pagana`

$H_0:$ jednorodność wariancji reszt.

$H_1:$ wariancja reszt zależy od zmiennych objaśniających w modelu.

```{r test BP MCD}
pv1 <- bptest(mod3)$p.value
```

P-value wynosi `r sprintf("%.10f",pv1)`, zatem Wug testu Breuscha-Pagana należałoby odrzucić hipotezę o jednorodności wariancji reszt.

- Test `Goldfelda-Quandta`

Weryfikacja hipotezy polega na podziale danych na dwie grupy i sprawdzeniu, czy w obu wariancja ma taką samą wartość.

$H_0:$ wariancja reszt jest równa w obu grupach.

$H_1:$ wariancja reszt różni się w obu grupach.

```{r test GQ MCD}
pv2 <- gqtest(mod3, order.by = ~fitted(mod3))$p.value
```

P-value wynosi `r sprintf("%.3f", pv2)`, zatem nie ma podstaw do odrzucenia hipotezy o równości wariancji.

- Test `Harrisona-McCabe'a`

Sprawdza hipotezę podobną do tej, którą weryfikuje test Goldfelda-Quandta; jednak w tym przypadku porównuje się zależność wariancji reszt dla całości obserwacji i wybranego kwantyla (w tym przypadku rzędu 0.5).

$H_0:$ wariancja reszt jest równa w porównywanych grupach.

$H_1:$ wariancja reszt różni się się w porównywanych grupach.

```{r test HMC MCD}
pv3 <- hmctest(mod3, order.by = ~fitted(mod3))$p.value
```

P-value wynosi jest praktycznie równe 0, należy przyjąć hipotezę alternatywną, czyli wariancja reszt modelu ulega zmianie.

Biorąc pod uwagę uzyskane wyniki, należy przyjąć, że reszty z modelu trzeciego stopnia nie są jednorodne.

#### Normalność

```{r wykres gęstości normalny MCD}
par(mfrow = c(1, 3))

plot(density(mod3$residuals), 
     main = "Wykres gęstości \n rozkładu reszt", ylab = "Gęstość")
curve(dnorm(x, 0, sd(mod3$residuals)), add = T, col = 2, lwd = 2)

qqnorm(mod3$residuals, main = "Wykres kwantylowy", xlab = "Wartości teoretyczne",
       ylab = "Wartość z próby")
qqline(mod3$residuals, col=2, lwd = 3)

plot(ecdf(mod3$residuals), 
     main = "Dystrybuanta empiryczna")
curve(pnorm(x, 0, sd(mod3$residuals)), add = T, col = 2, lwd =2)

par(mfrow=c(1, 1))
```


```{r testy normalności MCD}

kstest <- ks.test(x = mod3$residuals, y = "pnorm", mean = 0, sd = sd(mod3$residuals))$p.value
lillie <- lillie.test(mod3$residuals)$p.value
shapiro <- shapiro.test(mod3$residuals)$p.value
adtest <- ad.test(mod3$residuals)$p.value

```

Z testów Kołmogorowa-Lillieforsa, Shapiro-Wilka oraz Andersona-Darlinga wynika, że musimy odrzucić hipotezę o normalności rozkładu reszt (dla testu Kołmogorowa-Smirnova nie było podstaw do odrzucenia, p-value około `r kstest`). Jeżeli chodzi o wykresy, to brak normalności najbardziej widać na wykresie gęstości. Na drugim wykresie (z linią kwantylową) reszty najbardziej odstają od rozkładu normalnego na początku i na końcu. Dystrybuanta empiryczna jest zbliżona do dystrybuanty rozkładu normalnego.

#### Autokorelacja

- Test serii

$H_0:$ losowość

$H_1:$ brak losowości

```{r losowość reszt MCD}
Reszty <- mod3$residuals
runs.test(Reszty, threshold = 0, plot = T)
```

P-value bliskie zero, odrzucamy hipotezę o losowości reszt. Także na wykresie widać, że prawdopodobnie istnieje zależność między kolejnymi resztami, prawdopodobnie występuje autokorelacja.

- Test Durbina-Watsona

Weryfikuje hipotezę o niezależności reszt, sprawdzając, czy istotna jest autokorelacja reszt rzędu pierwszego.

```{r test DW MCD}
dwtest <- dwtest(mod3, order.by = ~t)$p.value
```

- Test Breuscha-Godfreya

```{r test BG MCD}
bgtest <- bgtest(mod3, order.by = ~t, order = 3)$p.value
```

- Wykres ACF (funkcji autokorelacji)

```{r test ACF - korelacja MCD}
acf(mod3$residuals, main = "Wykres funkcji autokorelacji")
```

Oba testy wskazują, że istnieje seryjna korelacja błędów, p-value w obu przypadkach jest praktycznie równe zero. Również z wykresu funkcji `acf` możemy wyciągnąć te same wnioski. Dla opóźnień do rzędu 25 obserwacje nie mieszczą się w niebieskich przerywanych liniach - wnioskujemy, że pojawia się autokorelacja.

- Wykres PACF (cząstkowej funkcji autokorelacji)

```{r test PACF MCD}
pacf(mod3$residuals, main = "Cząstkowa funkcja autokorelacji")
```

Wykres `PACF` jako jedyny nie wykrywa autokorelacji.

- Test Ljunga-Boxa

$H_0:$ niezależność

$H_1:$ brak niezależności

```{r box-ljung MCD}
lbox <- Box.test(mod3$residuals, type = "Ljung-Box")$p.value
```

P-value jest bardzo bliskie zero, odrzucamy hipotezę zerową, reszty nie są niezależne.

Ostatecznie stwierdzamy, że zachodzi autokorelacja reszt.

### Stacjonarność

Zbadamy, czy szereg jest stacjonarny albo TS (trend stationary).

Skorzystamy z dwóch testów :

- `adf` (Dickey-Fullera) 

$H_0:$ niestacjonarność

$H_1:$ stacjonarność

- `kpss` (Kwiatkowskiego-Phillipsa-Schmidta-Shina)

$H_0:$ stacjonarność

$H_1:$ niestacjonarność

```{r testy stacjonarność MCD}
adf <- adf.test(mcd)$p.value 
kpss <- kpss.test(mcd)$p.value 
kpsst <- kpss.test(mcd, null = "Trend")$p.value 
```

Po wykonaniu testów otrzymujemy wniosek, że szereg nie jest stacjonarny, ani stacjonarny wobec trendu.

```{r testy stacjonarność - różnicowanie MCD}
adf2 <- adf.test(diff(mcd, differences = 1))$p.value
kpss2 <- kpss.test(diff(mcd, differences = 1))$p.value 
kpsst2 <- kpss.test(diff(mcd, differences = 1), null = "Trend")$p.value
```

Po zróżnicowaniu 1 raz, szereg jest zarówno stacjonarny, jak i TS.

```{r}
n <- ndiffs(mcd)
```

Liczba różnicowań uzyskana za pomocą funkcji `ndiffs` wynosi `r n`, co zgadza się z wcześniejszymi wnioskami.

### ARIMA

Nasz szereg jest niestacjonarny, więc spróbujemy do niego dopasować model ARIMA.

```{r auto arima MCD}

auto.arima(mcd)
```

Według funkcji `auto.arima`, najlepszy model dla badanego szeregu czasowego to ARIMA(0, 1, 0), co oznacza, że nie ma składnika ani `AR` (Auto-Regressive), ani `MA` (Moving Average), a jedynie należy ten szereg zróżnicować jeden raz.

```{r arima(0,1,0) mcd}
mcd_arima <- arima(mcd, c(0,1,0))
```

Kryterium Akaike dla modelu ARIMA(0,1,0) wynosi `r mcd_arima$aic`, a wariancja `r mcd_arima$sigma2`

Na wszelki wypadek sprawdzimy dopasowanie kilku innych modeli ARIMA(p, r, q). Przyjmujemy $r=1$, jako że wcześniej otrzymaliśmy, że szereg należy zróżnicować jeden raz. Parametry $p$ i $q$ będą się zmieniać w pętlach od 0 do 3. Chcemy znaleźć najlepszy model ze względu na kryterium Akaike (tj. szukamy jak najmniejszego `aic`).

```{r spr różnich arim mcd}
akaike <- NULL
for (p in 0:3){
  akaike1 <- NULL
  for (q in 0:3){
    akaike1 <- c(akaike1, arima(mcd, c(p,1,q))$aic)
  
  }
  akaike <- rbind(akaike, akaike1)
  
}
akaike <- as.data.frame(akaike)
colnames(akaike) <- c("q=0", "q=1", "q=2", "q=3")
rownames(akaike) <- c("p=0", "p=1", "p=2", "p=3")
```

```{r tabelka akaike mcd, results = 'asis'}
kable(akaike) %>%
  kable_styling(full_width = T)
```

Z powyższej tabeli widać, że faktycznie najlepszym modelem jest ARIMA(0, 1, 0).

W takim razie nasz szereg można by zapisać jako:
$$\Delta\varepsilon_t=\epsilon_t$$
gdzie $\epsilon_t \sim N(0, 4.176)$.

#### Testy na resztach modelu ARIMA

Dla reszt otrzymanego modelu ARIMA można przeprowadzić testy na jednorodność wariancji oraz normalność rozkładu. Tak jak poprzednio, posłużymy się testami Breuscha-Pagana, Goldfelda-Quandta i Harrisona-McCabe'a dla zbadania jednorodności reszt oraz Kołmogorowa-Smirnova, Lillieforsa-Smirnova, Shapiro-Wilka i Andersona-Darlinga dla zbadania normalności.

NIE WIEM CZEMU, ALE TESTY NA JEDNORODNOŚĆ NIE CHCĄ MI PÓJŚĆ, NIE MAM JUŻ SIŁY OGARNIAĆ CO MU NIE PASUJE.

```{r}
#library(car)
#leveneTest(as.numeric(mcd_arima$fitted))
#bptest(mcd_arima)
#gqtest(mcd_arima)
#hmctest(mcd_arima)
```

- Normalność

```{r}
par(mfrow = c(1,3))
plot(density(mcd_arima$residuals), main = "Wykres gęstości \n rozkładu reszt",
     ylab = "Gęstość")
curve(dnorm(x,0, sd = sd(mcd_arima$residuals)), col = 2, add = T, lwd = 3)

qqnorm(mcd_arima$residuals, main = "Wykres kwantylowy", xlab = "Wartości teoretyczne", 
       ylab = "Wartości z próby")
qqline(mcd_arima$residuals, col = 2)

plot(ecdf(mcd_arima$residuals), main = "Dystybuanta empiryczna")
curve(pnorm(x,0, sd = sd(mcd_arima$residuals)), add = T, lwd = 3, col = 2)
par(mfrow = c(1,1))
```

Z wykresu gęstości rozkładu reszt można wnioskować, że prawdopodobnie ten rozkład charakteryzuje się dużą kurtozą, co powoduje jego "wyciągnięcie" w górę, natomiast z wykresu kwantylowego jasno wynika, że rozkład nie może być normalny. 

```{r}
ks.test(x = mcd_arima$residuals, y = "pnorm", mean = 0, sd = sd(mcd_arima$residuals))
lillie.test(mcd_arima$residuals)
shapiro.test(mcd_arima$residuals)
ad.test(mcd_arima$residuals)
```

Wszystkie testy jednoznacznie każą odrzucić hipotezę o normalności rozkładu reszt modelu ARIMA, co potwierdza wnioski, które nasuwają się patrząc na wykresy.

### Prognozowanie

#### Metoda dryftu

Ponieważ badany szereg czasowy nie wykazuje sezonowości, nie możemy zatem przeprowadzić predykcji metodą Holta-Wintersa. Zamiast tego użyjemy metody dryftu, będącej odmianą metody naiwnej. Dzięki niej można zaobserwować trend. 

```{r}
prognoza <- rwf(mcd, drift = T, h  = 30)
prognoza <- as.data.frame(prognoza)[,1]
plot(mcd, type = "l", main =  "Prognoza z całości danych na najbliższe 30 notowań",
     xlim = c(0,515), xlab = "Indeks notowań", ylab = "USD", lwd = 2)
t1 <- 503:(503+length(prognoza)-1)
lines(t1, prognoza, col = 3, lwd = 2)
```



```{r}
prognoza <- rwf(mcd[480:500], drift = T, h  = 30)
prognoza <- as.data.frame(prognoza)[,1]
plot(mcd, type = "l", main =  "Prognoza z ostatnich 20 notowań na najbliższe 30",
     xlim = c(0,515), xlab = "Indeks notowań", ylab = "USD", lwd = 2)
t1 <- 503:(503+length(prognoza)-1)
lines(t1, prognoza, col = 3, lwd = 2)
```

Z racji braku sezonowości, prognoza nie uwzględnia wahań, a jedynie ogólnie występujący trend. Z tego względu jest dość niedokładna i bardziej wiarygodne wyniki można uzyskać prognozując na krótsze odcinki czasu. Widać to z porównania powyższych wykresów - nachylenie linii prognozy, biorącej pod uwagę wszystkie wartości notowań jest mniejsze i nie uwzględnia istotnych zmian, które zaszły pomiędzy pierwszym a ostatnim notowaniem. 

#### Przewidywania z modelu

Próbujemy przewidywać z modelu wielomianowego trzeciego stopnia.

```{r}
wsp <- mod3$coefficients
funkcja <- function(t){
  wsp[1]+wsp[2]*t+wsp[3]*t^2+wsp[4]*t^3
}
t2 <- 503:520
plot(mcd, type = "l")
lines(t2, funkcja(t2))

```


### Podsumowanie analizy notowań McDonald's

Zrobiliśmy analizę. Nie umiemy jej zinterpretować. Jest fajnie.

## Starbucks

### Opis firmy

Starbucks Corporation – największa na świecie sieć kawiarni. Została założona 30 marca 1971 w Seattle w stanie Waszyngton.

### Wczytanie danych i rysunki

```{r wczytanie danych SBUX}
sbux<- get.hist.quote(instrument = "SBUX", provider = "yahoo",
                          quote = "Close", start = "2018-01-01", end = "2019-12-31")
sbux<- as.numeric(sbux)
```

Wykonamy rysunek przedstawiający notowania firmy Starbucks z ostatnich dwóch lat.

```{r rysunek notowań SBUX}
plot(sbux, type = "l", xlab = "Indeks notowań", ylab = "USD", main = "Notowania Starbucks")
```

Na rysunku możemy zaobserwować trend rosnący.

### Wydzielanie trendu
Wydzielamy część deterministyczną. Zastosujemy metody średnich ruchomych (prostą i wykładniczą).

### Ruchoma średnia
Skorzystamy z napisanej wcześniej funkcji `ruchoma`. Narysujmy wykresy dla kilku parametrów `m`.

```{r ruchoma SBUX}
par(mfrow=c(2,2))
ruchoma(sbux, 3, "red")
ruchoma(sbux, 10, "green")
ruchoma(sbux, 30, "blue")
ruchoma(sbux, 50, "pink")
par(mfrow=c(1,1))
```

Wraz ze wzrostem parametru `m` otrzymujemy bardziej wygładzony wykres, ale niestety mniej dokładny.

### Metoda wykładniczych wag ruchomej średniej

```{r wykładnicza SBUX}
par(mfrow=c(2,2))
wykladnicza(sbux, 0.2, "red")
wykladnicza(sbux, 0.5, "green")
wykladnicza(sbux, 0.7, "blue")
wykladnicza(sbux, 0.9, "pink")
par(mfrow=c(1,1))
```

Wraz ze wzrostem parametru $\eta$ uzyskujemy bardziej wygładzony wykres, ale mniejszą dokładność. Jest ona jednak większa niż w przypadku prostej metody ruchomej średniej.

### Dopasowanie wielomianu

### Metoda różnicowa

```{r różnicowanie - rysunki SBUX}
par(mfrow = c(2, 3))
for(i in 1:6){
plot(diff(sbux, differences = i), type = "l",
     xlab = "Numer obserwacji", ylab = paste("Różnicowanie rzędu ", i))
abline(h = 0)}
```

Z wykresów widać, że największa stabilizacja jest przy różnicowaniu rzędu 2 lub 3, potem rozrzut zaczyna się znacząco zwiększać.

```{r}
par(mfrow=c(1,1))
```

```{r zmienna t SBUX}
t <- 1:length(sbux)
```

#### Dopasowanie modelu liniowego

```{r model liniowy SBUX}
mod1 <- lm(sbux~t)
```

```{r model liniowy SBUX stargazer, results = 'asis'}
stargazer(mod1, header = F)
```

Wszystkie współczynniki są istotne statystycznie. $R^2$ wynosi około 79%.

```{r model liniowy - rysunki SBUX}
par(mfrow = c(1, 2))
plot(sbux, type = "l", main = "Model liniowy", xlab = "Indeks notowań", ylab = "USD")
abline(mod1, col = "red")
plot(mod1$residuals, type = "l", main = "Reszty modelu liniowego",
     xlab = "Indeks notowań", ylab = "Reszty")
abline(h=0)
```

Na wykresie widać, że reszty mają rozrzut mniej więcej od -10 do 15. Model nie jest zbyt dokładny - na początku przeszacowuje wartości, potem zdecydowanie nie doszacowuje, na koniec znowu przeszacowuje.

#### Dopasowanie wielomianu drugiego stopnia
```{r drugi stopień SBUX}
mod2 <- lm(sbux~t+I(t^2))
```

```{r drugi stopień SBUX stargazer, results = 'asis'}
stargazer(mod2, header = F)
```

Współczynnik przy t jest nieistotny statystycznie (p-value około 0.08, więc decyzja niejednoznaczna), ale $R^2$ poprawiło się - wynosi teraz około 83%.

```{r drugi stopień - rysunki SBUX}
par(mfrow = c(1, 2))
plot(sbux, type = "l", main = "Model wielomianowy \n drugiego stopnia",
     xlab = "Indeks notowań", ylab = "USD")
lines(t, mod2$fitted.values, col = "red")
plot(mod2$residuals, type = "l", main = "Reszty modelu \nwielomianowego \ndrugiego stopnia",
     xlab = "Indeks notowań", ylab = "Reszty")
abline(h = 0)
par(mfrow = c(1, 1))
```

Wykres reszt jest bardzo podobny jak w przypadku modelu liniowego.

#### Dopasowanie wielomianu trzeciego stopnia
```{r trzeci stopień SBUX}
mod3 <- lm(sbux~t+I(t^2)+I(t^3))
```

```{r trzeci stopień SBUX stargazer, results = 'asis'}
stargazer(mod3, header = F)
```

Wszystkie współczynniki są istotne statystycznie, a $R^2$ znów wzrosło - wynosi około 92% (znaczna poprawa).

```{r trzeci stopień - rysunki SBUX}
par(mfrow = c(1,2))
plot(sbux, type = "l", main = "Model wielomianowy \ntrzeciego stopnia",
     xlab = "Indeks notowań", ylab = "USD")
lines(t, mod3$fitted.values, col = "red")
plot(mod3$residuals, type = "l", main = "Reszty modelu \nwielomianowego \ntrzeciego stopnia",
     xlab = "Indeks notowań", ylab = "Reszty")
abline(h= 0)
par(mfrow=c(1,1))
```

Reszty modelu mają mniejszy rozrzut niż w poprzednich przypadkach (od około -5 do 10).

#### Dopasowanie wielomianu czwartego stopnia

```{r czwarty stopień SBUX}
mod4 <- lm(sbux~t+I(t^2)+I(t^3)+I(t^4))
```

```{r czwarty stopień SBUX stargazer, results='asis'}
stargazer(mod4, header = F)
```

```{r czwarty stopień - wykresy SBUX}
par(mfrow = c(1,2))
plot(sbux, type = "l", main = "Model wielomianowy \nczwartego stopnia", 
     xlab = "Indeks notowań", ylab = "USD")
lines(t, mod4$fitted.values, col = "red")
plot(mod4$residuals, type = "l", 
     main = "Reszty modelu \nwielomianowego \nczwartego stopnia", 
     xlab = "Indeks notowań", ylab = "Reszty")
abline(h= 0)
par(mfrow=c(1,1))
```


### Testy na resztach modelu

```{r losowość reszt SBUX}
Reszty <- mod3$residuals
runs.test(Reszty, threshold = 0, plot = T)
```

P-value jest bliskie 0, odrzucamy hipotezę zerową o losowości reszt. Wykres także wskazuje na skorelowanie reszt.


Wykresy normalności

```{r wykresy normalności SBUX}
plot(density(mod3$residuals), main = "Wykres gęstości \n rozkładu reszt", 
     ylab = "Gęstość")
curve(dnorm(x, 0, sd(mod3$residuals)), add = T, col = 2, lwd = 2)

qqnorm(mod3$residuals, main = "Wykres kwantylowy",
       xlab = "Wartości teoretyczne", ylab = "Wartości z próby")
qqline(mod3$residuals, col=2, lwd = 3)

plot(ecdf(mod3$residuals), main = "Dystrybuanta empiryczna")
curve(pnorm(x, 0, sd(mod3$residuals)), add = T, col = 2, lwd =2)
```

Wykres gęstości rozkładu reszt bardzo znacząco różni się od gęstości rozkładu normalnego. Widać, że rozkład jest co najmniej dwumodalny i ma zbyt silną asymetrię prawostronną. Na wykresie kwantylowym widać znaczące odchyłki od linii kwantylowej. Podobne zjawisko można zaobserwować na wykresie dystrybuanty empirycznej.

```{r testy normalności SBUX}
ks.test(x = mod3$residuals, y = "pnorm", mean = 0, sd = sd(mod3$residuals))
lillie.test(mod3$residuals) 
shapiro.test(mod3$residuals) 
ad.test(mod3$residuals)
```

W każdym z testów p-value jest bardzo bliskie zero, stanowczo odrzucamy hipotezę o rozkładzie normalnym.

Badanie autokorelacji

```{r test ACF - korelacja SBUX}
acf(mod3$residuals, main = "Funkcja autokorelacji")
```

Słupki nie mieszczą się w niebieskim "pasku", zatem prawdopodobnie ma miejsce autokorelacja.

### Stacjonarność

```{r stacjonarność - testy SBUX}
adf.test(sbux)
kpss.test(sbux)
kpss.test(sbux, null = "Trend")
```

Szereg nie jest ani stacjonarny ani TS.


```{r stacjonarność - testy po zróżnicowaniu SBUX}
adf.test(diff(sbux, differences = 1)) #st
kpss.test(diff(sbux, differences = 1)) #st
kpss.test(diff(sbux, differences = 1), null = "Trend") #st
```

Po zróżnicowaniu rzędu 1 szereg jest zarówno stacjonarny jak i TS.

```{r auto-arima SBUX}
auto.arima(sbux)
```

### Podsumowanie analizy notowań Starbucks


