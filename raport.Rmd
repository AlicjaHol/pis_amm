---
lang: pl
title: "Analiza szeregów czasowych - notowania giełdowe firm McDonald's oraz Starbucks"
author: "Alicja Hołowiecka, Matylda Jankowska, Marcin Dziadosz"
date: "23 12 2019"
output:
  
  pdf_document:
    toc: yes
    toc_depth: '4'
  html_document:
    theme: united
    toc: yes
    toc_depth: 4
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
```

# Matylda!! (to do, to do, to do to do to do to doooooooo)

- estetycznie można trochę poprawić, np. jak są te testy kpss i inne, to na razie robiłam tak, żeby wyświetlało ten domyślny output, może zamiast tego zrób tak jak Ty robiłaś w testach, że zapisać p-value do zmiennej i opisać? i popatrz jak wyglądają wykresy, szczególnie w pdf, może coś nie wygląda tak dobrze jak się nam wydawało, np tytuły się nie mieszczą, albo coś jest za bardzo ściśnięte, np wiem że te wykresy dla wielomianu 4 stopnia z nieznanych dla mnie przyczyn strasznie odwalają w pdf

- jeżeli nadal coś się nie zgadza z tą kolejnością co Kozłowski proponował, to możesz poprzestawiać

- co do opisów firm - ze Starbucksa trzeba wywalić zdjęcia bo dupnie wyglądają w pdf. I nie wiem czy ewentualnie z neta nie skopiować ze dwa zdania więcej do każdego, bo jakoś blado. spadliśmy już do 44 stron także jest coraz lepiej :) a jak wywalimy rysunki to jeszcze kolejne 3-4 strony pójdą

- sprawdź, jak wyglądają tabelki w pdfie - czy na pewno każda się wyświetla dokładnie gdzie ma być. Jeśli nie, to np dla tabelek robionych poprzez `kable_styling` można dodawać parametry: ` position = 'center'`, `latex_options = "HOLD_position"` i powinny się trzymać swojego miejsca

- za Chiny ludowe nie wiem jak robić jakieś prognozy czy cokolwiek... bo ten holt winters to chyba tylko dla sezonowych idzie. zobacz czy coś się da, a jak nie to usuwaj to gadowstwo.

- co do ARIMY - opisałam tak, jak na laborkach robiliśmy, zobacz czy z tego modelu da się wyciągnąć reszty i robić na nich testy. jeśli się da, to zrób te testy

- myślałam żeby na koniec każdej z tych firm zrobić takie podsumowanie - że np dla McDonalda z modelów wielomianowych najlepszy był taki i taki, jego reszty spełniają/nie spełniają cośtam, oprócz tego dopasowaliśmy model ARIMA taki śmaki, jego reszty cośtam cośtam... jakieś takie ładne sratatata na zakończenie

- pracuj przede wszystkim nad McDonaldem, potem Marcin spisze do Starbucksa. Chociaż tam też oczywiście możesz coś zacząć żeby mu ułatwić.

## Wstęp

W tym raporcie przeanalizujemy dwa szeregi czasowe: notowania firm McDonald's oraz Starbucks z okresu dwóch lat (od początku 2018 do końca 2019). Na potrzeby oceny w raporcie pojawia się nie tylko sama analiza, ale też wszystkie polecenia w języku `R`, jakich używaliśmy w jej celu.

## Wczytanie bibliotek

Na początek wczytamy wszystkie potrzebne biblioteki. Biblioteka `tseries` przyda nam się m. in. do wczytania danych oraz wykonania testów na stacjonarność szeregu. Z pakietu `randtests` skorzystamy przy testach na losowość reszt. W bibliotece `nortest` znajduje się wiele testów na normalność. Dzięki paczce `lmtest` utworzymy modele wielomianowe różnego stopnia i zbadamy ich dopasowanie. W bibliotece `forecast` są m. in. funkcje dotyczące modeli ARIMA. Pakiety `stargazer`, `tables` i `kableExtra` pozwolą nam estetycznie wyświetlać tabele.

```{r biblioteki}
library(tseries)
library(randtests)
library(nortest)
library(lmtest)
library(forecast)
library(stargazer)
library(kableExtra)
library(tidyverse)
library(tables)
```

## McDonald's

### Opis firmy

McDonald's to największa na świecie sieć restauracji szybkiej obsługi. Obejmuje ona ponad 30 tys. restauracji, każdego dnia obsługujących ponad 46 mln osób w 119 krajach. Wartość marki McDonald's szacuje się na 24,7 mld dolarów.




### Wczytanie danych i rysunki





Dane pobieramy z `yahoo finance` za pomocą funkcji `get.hist.quote` i zamieniamy na typ numeryczny.

```{r wczytanie danych MCD}
mcd<- get.hist.quote(instrument = "MCD", provider = "yahoo",
                          quote = "Close", start = "2018-01-01", end = "2019-12-31")
mcd <- as.numeric(mcd)
```

Wykonamy rysunek przedstawiający notowania firmy McDonald's od 01-01-2018 do 31-12-2019

```{r rysunek notowań MCD}
plot(mcd, type = "l", xlab = "czas", ylab = "USD", main = "Notowania McDonald's")
```
 
Na rysunku w ciągu tych dwóch lat wyraźnie widać trend rosnący.


### Wydzielanie trendu

Spróbujemy wydzielić część deterministyczną. Do tego celu posłużymy się metodami średnich ruchomych (prostą i wykładniczą).

#### Ruchoma średnia

Wykorzystamy metody ruchomych średnich, aby wygładzić szereg i zaobserwować ogólne trendy. Metoda średniej ruchomej ma na celu zmniejszenie rozrzutu razy $m+1$. 

W metodzie średniej ruchomej estymator części deterministycznej ma postać

$$\hat{f}(t) = \frac{1}{m+1}\sum_{k = 0}^{m}x_{t-k}$$

Do wykonania wygładzonych wykresów napisaliśmy funkcję `ruchoma`, której argumentami są `x` - szereg czasowy, `m` - paramter metody średniej ruchomej, `kolor` - kolor, na jaki dorysujemy wygładzoną linię na wykresie.

```{r funkcja ruchoma}
ruchoma <- function(x, m, kolor){
  t <- length(x)
  f <- NULL
  for(i in (m+1):t){
    f[i] <- mean(x[(i-m):i])
  }
  tytul = paste("Średnia ruchoma rzędu ", m)
  plot(x, type = "l", main = tytul)
  lines((m+1):t, f[(m+1):t], lwd = 2, col = kolor)
}
```

Narysujemy wykresy dla kilku parametrów `m`.



```{r ruchoma MCD}
par(mfrow = c(2, 2))
ruchoma(mcd, 3, "red")
ruchoma(mcd, 10, "green")
ruchoma(mcd, 30, "blue")
ruchoma(mcd, 50, "pink")
par(mfrow = c(1, 1))
```



Jak widać, im większy parametr `m` przyjmiemy, tym bardziej wygładzony wykres uzyskujemy, ale też mniej dokładny.

#### Metoda wykładniczych wag ruchomej średniej

W metodzie ruchomej średniej obserwacje starsze i nowsze mają taką samą wagę, dlatego ta metoda jest mało dokładna. Skorzystamy teraz z dokładniejszej metody wykładniczych wag ruchomej średniej.

W tej metodzie estymator części deterministycznej ma postać:

$$\hat{f}(t) = \frac{1 - \eta}{1-\eta^t}\sum_{k = 0}^{t-1}\eta^kx_{t-k}$$

gdzie $\eta \in (0, 1)$

Skorzystamy z postaci rekurencyjnej:

$$\hat{f}(t)=\frac{1- \eta}{1 - \eta^t}\left[x_t+ \eta \frac{1 - \eta^{t-1}}{1 - \eta} \hat{f}(t-1) \right]$$

```{r funkcja wykładnicza}
wykladnicza <- function(x, mi, kolor){
  f <- NULL
  f[1] <- x[1]
  
  for (i in 2:length(x)){
    f[i] <- (1-mi)/(1-mi^i)*(x[i]+mi*(1-mi^(i-1))/(1-mi)*f[i-1])
  }
  tytul = paste("średnia ruchoma z wagami wykładniczymi z parametrem ", mi)
  plot(x, type = "l", main = tytul)
  lines(1:length(x), f, lwd = 2, col = kolor)
}
```




```{r wykładnicza MCD}
par(mfrow = c(2, 2))
wykladnicza(mcd, 0.2, "red")
wykladnicza(mcd, 0.5, "green")
wykladnicza(mcd, 0.7, "blue")
wykladnicza(mcd, 0.9, "pink")
par(mfrow = c(1, 1))
```



Podobnie jak w przypadku prostej metody średniej ruchomej - im większy parametr $\eta$, tym bardziej wygładzony wykres, ale i mniejsza dokładność. Jednakże, dokładność jest i tak większa niż w przypadku prostej metody ruchomej średniej.

### Dopasowanie wielomianu

#### Metoda różnicowa

Za pomocą metody różnicowej sprawdzimy, jaki stopień wielomianu byłby najbardziej odpowiedni.

```{r różnicowanie - rysunki MCD}
par(mfrow = c(2, 3))
for(i in 1:6){
plot(diff(mcd, differences = i), type = "l")
abline(h = 0)}
par(mfrow=c(1,1))
```


Spróbujemy do danych dopasować wielomian stopnia 1, 2, 3 i 4.


```{r zmienna t MCD}
t <- 1:length(mcd)
```

#### Dopasowanie modelu liniowego

```{r model liniowy MCD}

mod1 <- lm(mcd~t)

```

```{r model liniowy MCD stargazer, results = 'asis'}
stargazer(mod1, header = F)
```


Zarówno wyraz wolny, jak i współczynnik kierunkowy są istotne statystycznie. $R^2$ wynosi około 74%.

```{r model liniowy - wykresy MCD} 
par(mfrow = c(1, 2))
plot(mcd, type = "l", main = "Model liniowy", xlab = "czas", ylab = "USD")
abline(mod1, col = "red")
plot(mod1$residuals, type = "l", 
     main = "Reszty modelu liniowego", xlab = "czas", ylab = "reszty")
abline(h=0)
par(mfrow = c(1, 1))
```

#### Dopasowanie wielomianem drugiego stopnia

Teraz stworzymy model wielomianowy drugiego stopnia.

```{r drugi stopień MCD}
mod2 <- lm(mcd~t+I(t^2))
```

```{r drugi stopień MCD stargazer, results = 'asis'}
stargazer(mod2, header = F)
```

Wszystkie współczynniki są istotne statystycznie. $R^2$ wynosi około 75%, a więc zmieniło się bardzo nieznacznie.

```{r drugi stopień - wykresy MCD}
par(mfrow = c(1, 2))
plot(mcd, type = "l", main = "Model wielomianowy \n drugiego stopnia", 
     xlab = "czas", ylab = "USD")
lines(t, mod2$fitted.values, col = "red")
plot(mod2$residuals, type = "l", 
     main = "Reszty modelu \nwielomianowego \ndrugiego stopnia", 
     xlab = "czas", ylab = "reszty")
abline(h = 0)
par(mfrow = c(1, 1))
```

Model kwadratowy zachowuje się bardzo podobnie jak model liniowy.

#### Dopasowanie wielomianem trzeciego stopnia



```{r trzeci stopień MCD}
mod3 <- lm(mcd~t+I(t^2)+I(t^3))
```

```{r trzeci stopień MCD stargazer, results='asis'}
stargazer(mod3, header = F)
```

W modelu wielomianowym trzeciego stopnia wszystkie współczynniki są istotne statystycznie. $R^2$ wynosi 90%, a więc znacząco się poprawił w stosunku do poprzednich dwóch modeli.

```{r trzeci stopień - wykresy MCD}
par(mfrow = c(1, 2))
plot(mcd, type = "l", 
     main = "Model wielomianowy \ntrzeciego stopnia", 
     xlab = "czas", ylab = "USD")
lines(t, mod3$fitted.values, col = "red")
plot(mod3$residuals, type = "l", 
     main = "Reszty modelu \nwielomianowego \ntrzeciego stopnia", 
     xlab = "czas", ylab = "reszty")
abline(h= 0)
par(mfrow = c(1, 1))
```

Widać, że reszty modelu mają mniejszy rozrzut niż poprzednio - teraz mamy skalę od -15 do 15, a wcześniej było od -20 do 20.

#### Dopasowanie wielomianem czwartego stopnia

```{r czwarty stopień MCD}
mod4 <- lm(mcd~t+I(t^2)+I(t^3)+I(t^4))
```

```{r czwarty stopień MCD stargazer, results='asis'}
stargazer(mod4, header = F)
```

```{r czwarty stopień - wykresy MCD}
par(mfrow = c(1, 2))
plot(mcd, type = "l", main = "Model wielomianowy \nczwartego stopnia", 
     xlab = "czas", ylab = "USD")
lines(t, mod4$fitted.values, col = "red")
plot(mod3$residuals, type = "l", 
     main = "Reszty modelu \nwielomianowego \nczwartego stopnia", 
     xlab = "czas", ylab = "reszty")
abline(h= 0)
par(mfrow=c(1,1))
```

W modelu wielomianowym czwartego stopnia współczynnik przy $t^3$ jest nieistotny statystycznie, ale nie możemy go usunąć, ponieważ efekt wyższego rzędu ($t^4$) jest istotny. $R^2$ wynosi około 91%, więc niewiele się różni od modelu wielomianowego 3 stopnia. Reszty także znajdują się w podobnym przedziale jak w poprzednim modelu. Model z $t^4$ niewiele się różni od tego z $t^3$, dlatego do dalszych badań wykorzystamy model wielomianowy 3 stopnia.








### Testy na resztach modelu

Do danych dobraliśmy wcześniej model wielomianowy trzeciego stopnia. Teraz sprawdzimy, czy reszty tego modelu spełniają założenia:

- losowość

- jednorodność wariancji

- normalność




#### Jednorodność wariancji

Aby zbadać czy jednorodność reszt posłużymy się kilkoma popularnymi testami.

- Test `Breuscha-Pagana`

$H_0:$ jednorodność wariancji reszt.

$H_1:$ wariancja reszt zależy od zmiennych objaśniających w modelu.

```{r test BP MCD}

bptest(mod3)
pv1 <- bptest(mod3)$p.value
```

P-value wynosi `r sprintf("%.10f",pv1)`, zatem Wug testu Breuscha-Pagana należałoby odrzucić hipotezę o jednorodności wariancji reszt.

- Test `Goldfelda-Quandta`

Weryfikacja hipotezy polega na podziale danych na dwie grupy i sprawdzeniu, czy w obu wariancja ma taką samą wartość.

$H_0:$ wariancja reszt jest równa w obu grupach.

$H_1:$ wariancja reszt różni się w obu grupach.

```{r test GQ MCD}
gqtest(mod3, order.by = ~fitted(mod3))
pv2 <- gqtest(mod3, order.by = ~fitted(mod3))$p.value
```

P-value wynosi `r sprintf("%.3f", pv2)`, zatem nie ma podstaw do odrzucenia hipotezy o równości wariancji.

- Test `Harrisona-McCabe'a`

Sprawdza hipotezę podobną do tej, którą weryfikuje test Goldfelda-Quandta; jednak w tym przypadku porównuje się zależność wariancji reszt dla całości obserwacji i wybranego kwantyla (w tym przypadku rzędu 0.5).

$H_0:$ wariancja reszt jest równa w porównywanych grupach.

$H_1:$ wariancja reszt różni się się w porównywanych grupach.

```{r test HMC MCD}
hmctest(mod3, order.by = ~fitted(mod3))
pv3 <- hmctest(mod3, order.by = ~fitted(mod3))$p.value
```

P-value wynosi jest praktycznie równe 0, należy przyjąć hipotezę alternatywną, czyli wariancja reszt modelu ulega zmianie.

Biorąc pod uwagę uzyskane wyniki, należy przyjąć, że reszty z modelu trzeciego stopnia nie są jednorodne.

#### Normalność

```{r wykres gęstości normalny MCD}
par(mfrow = c(1, 3))

plot(density(mod3$residuals), 
     main = "Wykres gęstości \nrozkładu reszt w \nporównaniu z rozkładem normalnym")
curve(dnorm(x, 0, sd(mod3$residuals)), add = T, col = 2, lwd = 2)

qqnorm(mod3$residuals, main = "Wykres z linią kwantylową")
qqline(mod3$residuals, col=2, lwd = 3)

plot(ecdf(mod3$residuals), 
     main = "Dystrybuanta empiryczna \nw porównaniu z rozkładem \nnormalnym")
curve(pnorm(x, 0, sd(mod3$residuals)), add = T, col = 2, lwd =2)

par(mfrow=c(1, 1))
```

```{r wykres qq MCD}

```

```{r wykres dystrybuanty normalny MCD}

```

```{r testy normalności MCD}

ks.test(x = mod3$residuals, y = "pnorm", mean = 0, sd = sd(mod3$residuals))
lillie.test(mod3$residuals)
shapiro.test(mod3$residuals)
ad.test(mod3$residuals)

```

Z testów Kołmogorowa-Lillieforsa, Shapiro-Wilka oraz Andersona-Darlinga wynika, że musimy odrzucić hipotezę o normalności rozkładu reszt (dla testu Kołmogorowa-Smirnova nie było podstaw do odrzucenia, p-value około 0.14). Jeżeli chodzi o wykresy, to brak normalności najbardziej widać na wykresie gęstości. Na drugim wykresie (z linią kwantylową) reszty najbardziej odstają od rozkładu normalnego na początku i na końcu. Dystrybuanta empiryczna jest zbliżona do dystrybuanty rozkładu normalnego.

#### Autokorelacja

- Test serii

$H_0:$ losowość

$H_1:$ brak losowości

```{r losowość reszt MCD}

runs.test(mod3$residuals, threshold = 0, plot = T)
```

P-value bliskie zero, odrzucamy hipotezę o losowości reszt.

- Test Durbina-Watsona

Weryfikuje hipotezę o niezależności reszt, sprawdzając, czy istotna jest autokorelacja reszt rzędu pierwszego.

```{r test DW MCD}

dwtest(mod3, order.by = ~t)
```

- Test Breuscha-Godfreya

```{r test BG MCD}
bgtest(mod3, order.by = ~t, order = 3)
```

- Wykres ACF (funkcji autokorelacji)

```{r test ACF - korelacja MCD}
acf(mod3$residuals, main = "Wykres funkcji autokorelacji")
```

Oba testy wskazują, że istnieje seryjna korelacja błędów. Również z wykresu funkcji `acf` możemy wyciągnąć te same wnioski. Dla opóźnień do rzędu 25 obserwacje nie mieszczą się w niebieskich przerywanych liniach - wnioskujemy, że pojawia się autokorelacja.

- Wykres PACF (cząstkowej funkcji autokorelacji)

```{r test PACF MCD}
pacf(mod3$residuals, main = "Cząstkowa funkcja autokorelacji")
```

Wykres `PACF` jako jedyny nie wykrywa autokorelacji.

- Test Ljunga-Boxa

$H_0:$ niezależność

$H_1:$ brak niezależności

```{r box-ljung MCD}
Box.test(mod3$residuals, type = "Ljung-Box")
```

P-value jest bardzo bliskie zero, odrzucamy hipotezę zerową, reszty nie są niezależne.

Ostatecznie stwierdzamy, że zachodzi autokorelacja reszt.

### Stacjonarność

Zbadamy, czy szereg jest stacjonarny albo TS (trend stationary).

Skorzystamy z dwóch testów :

- `adf` (Dickey-Fullera) 

$H_0:$ niestacjonarność

$H_1:$ stacjonarność

- `kpss` (Kwiatkowskiego-Phillipsa-Schmidta-Shina)

$H_0:$ stacjonarność

$H_1:$ niestacjonarność

```{r testy stacjonarność MCD}
adf.test(mcd) 
kpss.test(mcd) 
kpss.test(mcd, null = "Trend") 

```

Po wykonaniu testów otrzymujemy wniosek, że szereg nie jest stacjonarny, ani stacjonarny wobec trendu.

```{r testy stacjonarność - różnicowanie MCD}
adf.test(diff(mcd, differences = 1)) #stacj
kpss.test(diff(mcd, differences = 1)) #stacj
kpss.test(diff(mcd, differences = 1), null = "Trend") #stacj
```

Po zróżnicowaniu 1 raz, szereg jest zarówno stacjonarny, jak i TS.

```{r}
n <- ndiffs(mcd)
```

Liczba różnicowań uzyskana za pomocą funkcji `ndiffs` wynosi `r n`, co zgadza się z wcześniejszymi wnioskami.




### ARIMA

Nasz szereg jest niestacjonarny, więc spróbujemy do niego dopasować model ARIMA.

```{r auto arima MCD}

auto.arima(mcd)
```

Według funkcji `auto.arima`, najlepszy model dla badanego szeregu czasowego to ARIMA(0, 1, 0), co oznacza, że nie ma składnika ani `AR` (Auto-Regressive), ani `MA` (Moving Average), a jedynie należy ten szereg zróżnicować jeden raz.

```{r arima(0,1,0) mcd}
mcd_arima <- arima(mcd, c(0,1,0))
```

Kryterium AKAIKE dla modelu ARIMA(0,1,0) wynosi `r mcd_arima$aic`, a wariancja `r mcd_arima$sigma2`

Na wszelki wypadek sprawdzimy dopasowanie kilku innych modeli ARIMA(p, r, q). Przyjmujemy $r=1$, jako że wcześniej otrzymaliśmy, że szereg należy zróżnicować jeden raz. Parametry $p$ i $q$ będą się zmieniać w pętlach od 0 do 3. Chcemy znaleźć najlepszy model ze względu na kryterium Akaike (tj. szukamy jak najmniejszego `aic`).

```{r spr różnich arim mcd}
akaike <- NULL
for (p in 0:3){
  akaike1 <- NULL
  for (q in 0:3){
    akaike1 <- c(akaike1, arima(mcd, c(p,1,q))$aic)
  
  }
  akaike <- rbind(akaike, akaike1)
  
}
akaike <- as.data.frame(akaike)
colnames(akaike) <- c("q=0", "q=1", "q=2", "q=3")
rownames(akaike) <- c("p=0", "p=1", "p=2", "p=3")
```

```{r tabelka akaike mcd, results = 'asis'}
kable(akaike) %>%
  kable_styling(full_width = T)
```

Z powyższej tabeli widać, że faktycznie najlepszym modelem jest ARIMA(0, 1, 0).

W takim razie nasz szereg można by zapisać jako:
$$\Delta\varepsilon_t=\epsilon_t$$
gdzie $\epsilon_t \sim N(0, 4.176)$.

### Holt - Winters

ZA CHOLERĘ NIE WIEM JAK TYM ZROBIĆ PREDYKCJĘ BEZ SEZONOWOŚCI. Jak ktoś coś wie to niech robi. Pozdro.


### Podsumowanie analizy notowań McDonald's

Zrobiliśmy analizę. Nie umiemy jej zinterpretować. Jest fajnie.

## Starbucks

### Opis firmy

Starbucks Corporation – największa na świecie sieć kawiarni. Została założona 30 marca 1971 w Seattle w stanie Waszyngton.

### Wczytanie danych i rysunki

```{r wczytanie danych SBUX}
sbux<- get.hist.quote(instrument = "SBUX", provider = "yahoo",
                          quote = "Close", start = "2018-01-01", end = "2019-12-31")
sbux<- as.numeric(sbux)
```

Wykonamy rysunek przedstawiający notowania firmy Starbucks od 01-01-2018 do 31-12-2019.

```{r rysunek notowań SBUX}
plot(sbux, type = "l", xlab = "czas", ylab = "USD", main = "Notowania Starbucks")
```

Na rysunku możemy zaobserwować trend rosnący.

### Wydzielanie trendu
Wydzielamy część deterministyczną. Zastosujemy metody średnich ruchomych (prostą i wykładniczą).

### Ruchoma średnia
Skorzystamy z napisanej wcześniej funkcji `ruchoma`. Narysujmy wykresy dla kilku parametrów `m`.

```{r ruchoma SBUX}
par(mfrow=c(2,2))
ruchoma(sbux, 3, "red")
ruchoma(sbux, 10, "green")
ruchoma(sbux, 30, "blue")
ruchoma(sbux, 50, "pink")
par(mfrow=c(1,1))
```

Wraz ze wzrostem parametru `m` otrzymujemy bardziej wygładzony wykres, ale niestety mniej dokładny.

### Metoda wykładniczych wag ruchomej średniej

```{r wykładnicza SBUX}
par(mfrow=c(2,2))
wykladnicza(sbux, 0.2, "red")
wykladnicza(sbux, 0.5, "green")
wykladnicza(sbux, 0.7, "blue")
wykladnicza(sbux, 0.9, "pink")
par(mfrow=c(1,1))
```

Wraz ze wzrostem parametru $\eta$ uzyskujemy bardziej wygładzony wykres, ale mniejszą dokładność. Jest ona jednak większa niż w przypadku prostej metody ruchomej średniej.

### Dopasowanie wielomianu

### Metoda różnicowa

```{r różnicowanie - rysunki SBUX}
par(mfrow = c(2, 3))
for(i in 1:6){
plot(diff(sbux, differences = i), type = "l")
abline(h = 0)}
```

Z wykresów widać, że największa stabilizacja jest przy różnicowaniu rzędu 2 lub 3, potem rozrzut zaczyna się znacząco zwiększać.

```{r}
par(mfrow=c(1,1))
```

```{r zmienna t SBUX}
t <- 1:length(sbux)
```

#### Dopasowanie modelu liniowego
```{r model liniowy SBUX}
mod1 <- lm(sbux~t)
```

```{r model liniowy SBUX stargazer, results = 'asis'}
stargazer(mod1, header = F)
```

Wszystkie współczynniki są istotne statystycznie. $R^2$ wynosi około 79%.

```{r model liniowy - rysunki SBUX}
par(mfrow = c(1, 2))
plot(sbux, type = "l", main = "Model liniowy", xlab = "czas", ylab = "USD")
abline(mod1, col = "red")
plot(mod1$residuals, type = "l", main = "Reszty modelu liniowego", xlab = "czas", ylab = "reszty")
abline(h=0)
```

Na wykresie widać, że reszty mają rozrzut mniej więcej od -10 do 15. Model nie jest zbyt dokładny - na początku przeszacowuje wartości, potem zdecydowanie nie doszacowuje, na koniec znowu przeszacowuje.

#### Dopasowanie wielomianu drugiego stopnia
```{r drugi stopień SBUX}
mod2 <- lm(sbux~t+I(t^2))
```

```{r model liniowy SBUX stargazer, results = 'asis'}
stargazer(mod2, header = F)
```

Współczynnik przy t jest nieistotny statystycznie (p-value około 0.08, więc decyzja niejednoznaczna), ale $R^2$ poprawiło się - wynosi teraz około 83%.

```{r drugi stopień - rysunki SBUX}
par(mfrow = c(1, 2))
plot(sbux, type = "l", main = "Model wielomianowy \n drugiego stopnia", xlab = "czas", ylab = "USD")
lines(t, mod2$fitted.values, col = "red")
plot(mod2$residuals, type = "l", main = "Reszty modelu \nwielomianowego \ndrugiego stopnia", xlab = "czas", ylab = "reszty")
abline(h = 0)
par(mfrow = c(1, 1))
```

Wykres reszt jest bardzo podobny jak w przypadku modelu liniowego.

#### Dopasowanie wielomianu trzeciego stopnia
```{r trzeci stopień SBUX}
mod3 <- lm(sbux~t+I(t^2)+I(t^3))
```

```{r model liniowy SBUX stargazer, results = 'asis'}
stargazer(mod3, header = F)
```

Wszystkie współczynniki są istotne statystycznie, a $R^2$ znów wzrosło - wynosi około 92% (znaczna poprawa).

```{r trzeci stopień - rysunki SBUX}
par(mfrow = c(1,2))
plot(sbux, type = "l", main = "Model wielomianowy \ntrzeciego stopnia", xlab = "czas", ylab = "USD")
lines(t, mod3$fitted.values, col = "red")
plot(mod3$residuals, type = "l", main = "Reszty modelu \nwielomianowego \ntrzeciego stopnia", xlab = "czas", ylab = "reszty")
abline(h= 0)
par(mfrow=c(1,1))
```

Reszty modelu mają mniejszy rozrzut niż w poprzednich przypadkach (od około -5 do 10).

#### Dopasowanie wielomianu czwartego stopnia

```{r czwarty stopień SBUX}
mod4 <- lm(sbux~t+I(t^2)+I(t^3)+I(t^4))
```

```{r czwarty stopień SBUX stargazer, results='asis'}
stargazer(mod4, header = F)
```

```{r czwarty stopień - wykresy SBUX}
par(mfrow = c(1,2))
plot(sbux, type = "l", main = "Model wielomianowy \nczwartego stopnia", 
     xlab = "czas", ylab = "USD")
lines(t, mod4$fitted.values, col = "red")
plot(mod4$residuals, type = "l", 
     main = "Reszty modelu \nwielomianowego \nczwartego stopnia", 
     xlab = "czas", ylab = "reszty")
abline(h= 0)
par(mfrow=c(1,1))
```


### Testy na resztach modelu

```{r losowość reszt SBUX}
runs.test(mod3$residuals, threshold = 0, plot = T)
```
P-value jest bliskie 0, odrzucamy hipotezę zerową o losowości reszt

Wykresy normalności

```{r wykres gęstośi normalny SBUX}
plot(density(mod3$residuals))
curve(dnorm(x, 0, sd(mod3$residuals)), add = T, col = 2, lwd = 2)

```

Wykres gęstości empirycznej znacząco różni się od gęstości rozkładu normalnego. Bardzo znacząco.

```{r wykres qq SBUX}
qqnorm(mod3$residuals)
qqline(mod3$residuals, col=2, lwd = 3)
```

Tutaj także wyraźne odchyłki.

```{r wykres dystrybuanty normalny SBUX}
plot(ecdf(mod3$residuals))
curve(pnorm(x, 0, sd(mod3$residuals)), add = T, col = 2, lwd =2)
```

Nawet na dystrybuancie widać, że rozkład normalny wygląda inaczej.

```{r testy normalności SBUX}
ks.test(x = mod3$residuals, y = "pnorm", mean = 0, sd = sd(mod3$residuals))
lillie.test(mod3$residuals) 
shapiro.test(mod3$residuals) 
ad.test(mod3$residuals)
```

W każdym z testów p-value jest bardzo bliskie zero, stanowczo odrzucamy hipotezę o rozkładzie normalnym.

Badanie autokorelacji

```{r test ACF - korelacja SBUX}
acf(mod3$residuals)
```

Słupki nie mieszczą się w niebieskim "pasku", zatem prawdopodobnie ma miejsce autokorelacja.



### Stacjonarność
```{r stacjonarność - testy SBUX}
adf.test(sbux) #niest
kpss.test(sbux) #niest
kpss.test(sbux, null = "Trend") #niest

```

Szereg nie jest ani stacjonarny ani TS.


```{r stacjonarność - testy po zróżnicowaniu SBUX}
adf.test(diff(sbux, differences = 1)) #st
kpss.test(diff(sbux, differences = 1)) #st
kpss.test(diff(sbux, differences = 1), null = "Trend") #st
```

Po zróżnicowaniu rzędu 1 szereg jest zarówno stacjonarny jak i TS.

```{r auto-arima SBUX}
auto.arima(sbux)
```



